{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Факторизационная машина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# библиотеки\n",
    "\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# параметры данных\n",
    "n_movies = 17770\n",
    "n_users = 2649429\n",
    "n = n_movies + n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка и сбор данных в файл в подходящем формате csv\n",
    "\n",
    "combined_data_file_name = \"data/combined_data_%s.txt\"\n",
    "\n",
    "target_f = open(\"data/processed_data.csv\", \"w+\")\n",
    "for i in {1,2,3,4}:\n",
    "    print(\"Data file: \" + str(i) + \"/4\")\n",
    "    \n",
    "    cur_movie_id = None\n",
    "    with open(combined_data_file_name % i) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if (len(row) == 1):\n",
    "                cur_movie_id = row[0][:-1]\n",
    "            else:\n",
    "                user_id = row[0]\n",
    "                rating = row[1]\n",
    "                \n",
    "                target_f.write(user_id + \",\" + rating + \",\" + cur_movie_id + \"\\n\")\n",
    "target_f.close()\n",
    "\n",
    "\n",
    "# деление полученного файла на 5 в соответствии с количеством фолдов,\n",
    "# из-за не возможности работать с файлом целиком (нехватка памятя)\n",
    "\n",
    "target_f1 = open(\"data/processed_data1.csv\", \"w+\")\n",
    "target_f2 = open(\"data/processed_data2.csv\", \"w+\")\n",
    "target_f3 = open(\"data/processed_data3.csv\", \"w+\")\n",
    "target_f4 = open(\"data/processed_data4.csv\", \"w+\")\n",
    "target_f5 = open(\"data/processed_data5.csv\", \"w+\")\n",
    "i=1\n",
    "with open(\"data/processed_data.csv\") as csv_reader:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        if i == 1:\n",
    "            target_f1.write(row)\n",
    "            i+=1\n",
    "        elif i == 2:\n",
    "            target_f2.write(row)\n",
    "            i+=1\n",
    "        elif i == 3:\n",
    "            target_f3.write(row)\n",
    "            i+=1\n",
    "        elif i == 4:\n",
    "            target_f4.write(row)\n",
    "            i+=1\n",
    "        elif i == 5:\n",
    "            target_f5.write(row)\n",
    "            i=1\n",
    "target_f1.close()\n",
    "target_f2.close()\n",
    "target_f3.close()\n",
    "target_f4.close()\n",
    "target_f5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем для каждого файла матрицу в виде: one-hot-codding фильма и записываем в файл в формате npz\n",
    "# отдельно матрицу признаков и целевые значения\n",
    "\n",
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "\n",
    "dataFileName = \"data/processed_data%s.csv\"\n",
    "dataFileNameX = \"data/X%s.npz\"\n",
    "dataFileNameY = \"data/Y%s.npz\"\n",
    "\n",
    "for i in {1,2,3,4,5}:\n",
    "    print(\"Data file: \" + str(i) + \"/5\")\n",
    "    MovieData = pd.read_csv(dataFileName % i, header = None, names = ['User_Id','Rating','Movie_Id'])\n",
    "    for i in range(MovieData.shape[0]):\n",
    "        # собираем данные в массивы\n",
    "        data.append(1) # единица - пересечение пользователя и фильма\n",
    "        data.append(1) # единица - пересечение пользователя и фильма\n",
    "        data.append(MovieData['Rating'][i]) # рейтинг пользователя фильму\n",
    "        row.append(i)       # на одной строке\n",
    "        row.append(i)\n",
    "        row.append(i)\n",
    "        col.append(MovieData['Movie_Id'][i] - 1) # столбец фильма\n",
    "        col.append(MovieData['User_Id'][i] + MovieData['Movie_Id'][i] - 1) # столбец пользователя\n",
    "        col.append(n) # столбец целевых значений - рейтинг\n",
    "            \n",
    "        print(MovieData.shape)\n",
    "        MovieData=''\n",
    "        # разреженная матрица\n",
    "        CSRMatrix = sparse.csr_matrix((data, (row, col)), dtype=np.int8, shape=(i+1, n + 1))\n",
    "        data = []\n",
    "        row = []\n",
    "        col = []      \n",
    "        #  перемешиваем данные\n",
    "        CSRMatrix = shuffle(CSRMatrix)\n",
    "        #  разделяем матрицу признаков и целевые значения\n",
    "        X = CSRMatrix[:, :-1]\n",
    "        Y = CSRMatrix[:, -1]\n",
    "        sparse.save_npz(dataFileNameX % i, X)\n",
    "        sparse.save_npz(dataFileNameY % i, Y)\n",
    "        Y=''\n",
    "        X=''\n",
    "        CSRMatrix='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мини-батч градиентным спуском\n",
    "\n",
    "def gradDescentMiniBatch(ind, n, learningRate , maxIter):\n",
    "    bias = np.random.random(size=(n, 3))\n",
    "    w = np.random.random(size=(n, 1))\n",
    "    dataFileNameX = \"data/X%s.npz\"\n",
    "    dataFileNameY = \"data/Y%s.npz\"\n",
    "    # проходим по всем файлом отдело, из-за нехватки памяти\n",
    "    for i in {1,2,3,4,5}:\n",
    "        if i != ind:\n",
    "            start = time.time()\n",
    "            X=sparse.load_npz(dataFileNameX % i)\n",
    "            Y=sparse.load_npz(dataFileNameY % i)\n",
    "\n",
    "            for itr in range(maxIter):\n",
    "                batchSize = 131072  # размер батча 2**17\n",
    "                # делим данные на батчи\n",
    "                for idxB in range(int(X.shape[0] / batchSize + 1)):\n",
    "                    Xbatch = X[(idxB * batchSize):((idxB * batchSize) + batchSize)]\n",
    "                    yBatch = Y[(idxB * batchSize):((idxB * batchSize) + batchSize)]\n",
    "                    # подсчет коэффициентов\n",
    "                    batchTemp = Xbatch.dot(bias)\n",
    "                    yPred = Xbatch.dot(w) + (0.5 * np.sum((batchTemp ** 2) - Xbatch.dot(bias ** 2), axis=1)).reshape(Xbatch.shape[0], 1)\n",
    "                    dy = 2 * (yPred.reshape(yBatch.shape[0], 1) - yBatch.reshape(yBatch.shape[0], 1))\n",
    "                    wGrad = Xbatch.T.dot(dy)\n",
    "                    bGrad = (Xbatch.T.dot(batchTemp) - np.sum((Xbatch.multiply(Xbatch)), axis=0) * bias) * dy.mean() / Xbatch.shape[0]\n",
    "                    w -= learningRate * wGrad\n",
    "                    bias -= learningRate * bGrad\n",
    "\n",
    "            stop = time.time()\n",
    "            print(f'Data file: {i} time: {stop - start} seconds')\n",
    "        \n",
    "    return w, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогнозирование\n",
    "\n",
    "def getPrediction(X, w, bias):\n",
    "    return X.dot(w) + (0.5 * np.sum((X.dot(bias) ** 2) - X.dot(bias**2), axis=1)).reshape(X.shape[0],1)\n",
    "\n",
    "\n",
    "def getPredictionTrain(ind, w, bias):\n",
    "    \n",
    "    dataFileNameX = \"data/X%s.npz\"\n",
    "    prediction = []\n",
    "    for i in {1,2,3,4,5}:\n",
    "        if i != ind:\n",
    "            X = sparse.load_npz(dataFileNameX % i)\n",
    "            prediction.append(X.dot(w) + (0.5 * np.sum((X.dot(bias) ** 2) - X.dot(bias**2), axis=1)).reshape(X.shape[0],1))\n",
    "            \n",
    "    return np.vstack(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчет RMSE\n",
    "\n",
    "def getRMSE(y, yPred):\n",
    "    return np.sqrt(np.mean(np.square(y - yPred)))\n",
    "\n",
    "\n",
    "def getRMSETrain(ind, yPred):\n",
    "    \n",
    "    dataFileNameY = \"data/Y%s.npz\"\n",
    "    y = []\n",
    "    for i in {1,2,3,4,5}:\n",
    "        if i != ind:\n",
    "            y.append(sparse.load_npz(dataFileNameY % i))\n",
    "    y = sparse.vstack(y)\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(y - yPred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# основная функция - кросс-валидация\n",
    "\n",
    "def crossValidation(idx):\n",
    "    \n",
    "    dataFileNameX = \"data/X%s.npz\"\n",
    "    dataFileNameY = \"data/Y%s.npz\"\n",
    "    #данных для теста\n",
    "    TestX = sparse.load_npz(dataFileNameX%idx)\n",
    "    TestY = sparse.load_npz(dataFileNameY%idx)\n",
    "    \n",
    "    # обучение факторизационной машины \n",
    "    w,bias = gradDescentMiniBatch(idx, n, 0.0001, 3)\n",
    "\n",
    "    # прогнозирование\n",
    "    TrainPred = getPredictionTrain(idx, w, bias)\n",
    "    TestPred = getPrediction(TestX, w, bias)\n",
    "    # оценка\n",
    "    RMSE_train = getRMSETrain(idx, TrainPred)\n",
    "    RMSE_test = getRMSE(TestY, TestPred)\n",
    "\n",
    "    print(f'RMSE train: {RMSE_train}')\n",
    "    print(f'RMSE test: {RMSE_test}')\n",
    "\n",
    "    return RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: 2 time: 199.7283968925476 seconds\n",
      "Data file: 3 time: 197.72328329086304 seconds\n",
      "Data file: 4 time: 203.19793128967285 seconds\n",
      "Data file: 5 time: 195.22172689437866 seconds\n",
      "RMSE train: 1.1305099079895273\n",
      "RMSE test: 1.1312638020823116\n"
     ]
    }
   ],
   "source": [
    "RMSE =[]\n",
    "\n",
    "RMSE.append(crossValidation(1)) # параметр - номер файла, содержащий тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: 1 time: 188.26041746139526 seconds\n",
      "Data file: 3 time: 193.58615922927856 seconds\n",
      "Data file: 4 time: 197.55680298805237 seconds\n",
      "Data file: 5 time: 195.46213221549988 seconds\n",
      "RMSE train: 1.1313420422152807\n",
      "RMSE test: 1.1324282277401179\n"
     ]
    }
   ],
   "source": [
    "RMSE.append(crossValidation(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: 1 time: 188.06929278373718 seconds\n",
      "Data file: 2 time: 188.0104057788849 seconds\n",
      "Data file: 4 time: 192.82725858688354 seconds\n",
      "Data file: 5 time: 204.36627984046936 seconds\n",
      "RMSE train: 1.1305625800826835\n",
      "RMSE test: 1.1314099887768967\n"
     ]
    }
   ],
   "source": [
    "RMSE.append(crossValidation(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: 1 time: 167.1914553642273 seconds\n",
      "Data file: 2 time: 158.4792628288269 seconds\n",
      "Data file: 3 time: 158.84874200820923 seconds\n",
      "Data file: 5 time: 152.47674560546875 seconds\n",
      "RMSE train: 1.1301607211578755\n",
      "RMSE test: 1.1306830890754191\n"
     ]
    }
   ],
   "source": [
    "RMSE.append(crossValidation(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: 1 time: 144.21971821784973 seconds\n",
      "Data file: 2 time: 147.25142884254456 seconds\n",
      "Data file: 3 time: 150.87804079055786 seconds\n",
      "Data file: 4 time: 153.87776160240173 seconds\n",
      "RMSE train: 1.1307342724028633\n",
      "RMSE test: 1.1313122579985189\n"
     ]
    }
   ],
   "source": [
    "RMSE.append(crossValidation(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train\n",
      "[[1.13050991 1.13134204 1.13056258 1.13016072 1.13073427]]\n",
      "RMSE test\n",
      "[1.1312638  1.13242823 1.13140999 1.13068309 1.13131226]\n",
      "mean train\n",
      "1.1306619047696462\n",
      "mean test\n",
      "1.131419473134653\n",
      "std train\n",
      "0.0003878085730372459\n",
      "std test\n",
      "0.000564918728975363\n"
     ]
    }
   ],
   "source": [
    "# значение метрик RMSE\n",
    "# RM = np.vstack(RMSE)\n",
    "print('RMSE train')\n",
    "print(np.reshape(RM[:, :-1], (1, RM.shape[0])))\n",
    "print('RMSE test')\n",
    "print(RM[:, -1])\n",
    "print('mean train')\n",
    "print(np.mean(RM[:, :-1]))\n",
    "print('mean test')\n",
    "print(np.mean(RM[:, -1]))\n",
    "print('std train')\n",
    "print(np.std(RM[:, :-1]))\n",
    "print('std test')\n",
    "print(np.std(RM[:, -1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
